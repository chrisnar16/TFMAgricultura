{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5ba023-108d-4b74-8331-e78a7054004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semillas aleatorias configuradas a: 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa8aaf57c70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CherryTreeDataset import CherryTreeDataset\n",
    "from torchvision import transforms\n",
    "from funciones_auxiliares import plot_spectra, analyze_image, analyze_tiff_metadata, PATH, crop_central_region, set_seed, seed_worker\n",
    "from resnet_adapters import adapt_resnet_channels\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Subset\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet18_Weights, ResNet50_Weights\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
    "\n",
    "set_seed(42)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142e2225-0e32-410c-a7d2-2e1b1ebb5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dispositivo seleccionado es cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'El dispositivo seleccionado es {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb8529a-eba4-47c5-82bc-921a0b5924ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las transformaciones si son necesarias\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1280,960)),\n",
    "    #transforms.Lambda(lambda x: crop_central_region(x, center_ratio=0.8)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#formats = ('RGB.JPG', 'RED.TIF','GRE.TIF','NIR.TIF','REG.TIF')\n",
    "#formats = ('RGB.JPG','NIR.TIF','REG.TIF')\n",
    "formats = ('RGB.JPG',)\n",
    "input_channels = 3\n",
    "dataset = CherryTreeDataset(PATH, transform=transform, formats = formats, concatenate = True, balance=False)\n",
    "\n",
    "healthy_indices = []\n",
    "disease_indices = []\n",
    "    \n",
    "for i, (_, label) in enumerate(dataset.samples):\n",
    "    if label == 0:  # Healthy\n",
    "        healthy_indices.append(i)\n",
    "    else:  # Disease\n",
    "        disease_indices.append(i)\n",
    "    \n",
    "    # Dividir los índices de árboles sanos en entrenamiento y validación\n",
    "np.random.shuffle(healthy_indices)\n",
    "\n",
    "train_healthy = healthy_indices[:int(0.8 * len(healthy_indices))]\n",
    "test_healthy = healthy_indices[int(0.8 * len(healthy_indices)):]\n",
    "train_disease = disease_indices[:int(0.8 * len(disease_indices))]\n",
    "test_disease = disease_indices[int(0.8 * len(disease_indices)):]\n",
    "    \n",
    "    # Los índices de árboles enfermos solo se usan para testing\n",
    "    # Create datasets\n",
    "train_dataset = Subset(dataset, train_healthy)\n",
    "val_dataset = Subset(dataset, test_healthy + test_disease)  # Incluimos enfermos solo para evaluación\n",
    "    \n",
    "    # Crear dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, worker_init_fn=seed_worker)\n",
    "test_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, worker_init_fn=seed_worker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6dc02b-e4eb-46cc-974a-32f5ac7526b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder: Reducción progresiva de la dimensionalidad a través de más capas convolucionales\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 1280x960 -> 640x480\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 640x480 -> 320x240\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 320x240 -> 160x120\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 160x120 -> 80x60\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 80x60 -> 40x30\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 40x30 -> 20x15\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Tamaño del feature map después del encoder: 20x15 con 512 canales\n",
    "        self.encoder_output_h = 15\n",
    "        self.encoder_output_w = 20\n",
    "        self.encoder_output_channels = 512\n",
    "        \n",
    "        # Capa de proyección para reducir dimensionalidad antes de capas fully-connected\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((8, 8)),  # Reduce a 8x8 independientemente del tamaño de entrada\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 8 * 8, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Capas para generar la media y el log de la varianza\n",
    "        self.fc_mu = nn.Linear(1024, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(1024, latent_dim)\n",
    "        \n",
    "        # Capa para pasar del espacio latente a la forma del decoder\n",
    "        self.fc_decoder = nn.Linear(latent_dim, 512 * 8 * 8)\n",
    "        \n",
    "        # Capa de desproyección para recuperar la dimensionalidad antes de deconvoluciones\n",
    "        self.unprojection = nn.Sequential(\n",
    "            nn.Linear(512 * 8 * 8, 512 * self.encoder_output_h * self.encoder_output_w),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            # 20x15 -> 40x30\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 40x30 -> 80x60\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 80x60 -> 160x120\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 160x120 -> 320x240\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 320x240 -> 640x480\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 640x480 -> 1280x960\n",
    "            nn.ConvTranspose2d(16, input_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Inicialización de pesos\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Propagación hacia adelante del encoder y decoder\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def encode(self, x):\n",
    "        # Codificar mediante convoluciones\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # Proyectar a menor dimensionalidad\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        # Calcular mu y log_var\n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_log_var(x)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        # Trick de reparametrización\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        # Del espacio latente a la forma para el decoder\n",
    "        x = self.fc_decoder(z)\n",
    "        x = x.view(x.size(0), 512, 8, 8)\n",
    "        \n",
    "        # Desproyectar a la dimensión original\n",
    "        x = self.unprojection(x.flatten(1))\n",
    "        x = x.view(x.size(0), 512, self.encoder_output_h, self.encoder_output_w)\n",
    "        \n",
    "        # Decodificar mediante transposición de convoluciones\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, log_va\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # Inicialización de los pesos de manera más robusta\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu', generator=torch.Generator().manual_seed(42))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class VAEAnomalyDetector:\n",
    "    def __init__(self, input_channels, device='cuda', latent_dim=256,beta=1.0):\n",
    "        self.device = device\n",
    "        self.model = VariationalAutoencoder(input_channels).to(device)\n",
    "        self.input_channels = input_channels\n",
    "        self.threshold = None\n",
    "        self.latent_dim = latent_dim\n",
    "        self.beta = beta # Factor de peso para el término KL\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, log_var):\n",
    "        # Error de reconstrucción (MSE)\n",
    "        recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "        \n",
    "        # Divergencia KL\n",
    "        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Pérdida total\n",
    "        total_loss = recon_loss + self.beta * kl_loss\n",
    "        \n",
    "        return total_loss, recon_loss, kl_loss\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs=50, lr=1e-3, weight_decay=1e-5, beta_annealing=True):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        \n",
    "        # Para almacenar las pérdidas\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        # Beta annealing: aumentar beta gradualmente\n",
    "        initial_beta = 0.0\n",
    "        final_beta = self.beta\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Actualizar beta si se usa annealing\n",
    "            if beta_annealing:\n",
    "                self.beta = initial_beta + (final_beta - initial_beta) * min(1.0, epoch / (epochs / 3))\n",
    "            \n",
    "            # ----- Entrenamiento -----\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            train_recon_loss = 0\n",
    "            train_kl_loss = 0\n",
    "            \n",
    "            for data, _ in train_loader:\n",
    "                # Solo usar árboles sanos para entrenar\n",
    "                healthy_mask = _ == 0\n",
    "                if not any(healthy_mask):\n",
    "                    continue\n",
    "                \n",
    "                data = data[healthy_mask].to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                recon_batch, mu, log_var = self.model(data)\n",
    "                \n",
    "                # Calcular pérdida\n",
    "                loss, recon, kl = self.loss_function(recon_batch, data, mu, log_var)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                train_recon_loss += recon.item()\n",
    "                train_kl_loss += kl.item()\n",
    "            \n",
    "            n_batches = len(train_loader)\n",
    "            train_loss /= n_batches\n",
    "            train_recon_loss /= n_batches\n",
    "            train_kl_loss /= n_batches\n",
    "            train_losses.append(train_loss)\n",
    "            \n",
    "            # ----- Validación -----\n",
    "            self.model.eval()\n",
    "            val_loss = 0\n",
    "            val_recon_loss = 0\n",
    "            val_kl_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for data, _ in val_loader:\n",
    "                    healthy_mask = _ == 0\n",
    "                    if not any(healthy_mask):\n",
    "                        continue\n",
    "                    \n",
    "                    data = data[healthy_mask].to(self.device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    recon_batch, mu, log_var = self.model(data)\n",
    "                    \n",
    "                    # Calcular pérdida\n",
    "                    loss, recon, kl = self.loss_function(recon_batch, data, mu, log_var)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    val_recon_loss += recon.item()\n",
    "                    val_kl_loss += kl.item()\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            val_recon_loss /= len(val_loader)\n",
    "            val_kl_loss /= len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            # Actualizar scheduler\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), 'best_vae_anomaly_detector.pth')\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{epochs}, Beta: {self.beta:.2f}, Train Loss: {train_loss:.4f} '\n",
    "                  f'(Recon: {train_recon_loss:.4f}, KL: {train_kl_loss:.4f}), '\n",
    "                  f'Val Loss: {val_loss:.4f} (Recon: {val_recon_loss:.4f}, KL: {val_kl_loss:.4f})')\n",
    "        \n",
    "        # Cargar el mejor modelo\n",
    "        self.model.load_state_dict(torch.load('best_vae_anomaly_detector.pth'))\n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    def anomaly_score(self, x):\n",
    "        \"\"\"Calcula la puntuación de anomalía para una imagen\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x_recon, mu, log_var = self.model(x)\n",
    "            \n",
    "            # Error de reconstrucción\n",
    "            recon_error = F.mse_loss(x_recon, x, reduction='none').mean(dim=[1, 2, 3])\n",
    "            \n",
    "            # Divergencia KL\n",
    "            kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=1)\n",
    "            \n",
    "            # Puntuación de anomalía combinada\n",
    "            score = recon_error + self.beta * kl_div\n",
    "            \n",
    "            return score, recon_error, kl_div\n",
    "\n",
    "    def calculate_threshold(self, val_loader, percentile=95):\n",
    "        \"\"\"Calcula el umbral de detección basado en los datos de validación de árboles sanos\"\"\"\n",
    "        self.model.eval()\n",
    "        anomaly_scores = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, labels in val_loader:\n",
    "                # Solo usar árboles sanos para calibrar el umbral\n",
    "                healthy_mask = labels == 0\n",
    "                if not any(healthy_mask):\n",
    "                    continue\n",
    "                \n",
    "                healthy_data = data[healthy_mask].to(self.device)\n",
    "                scores, _, _ = self.anomaly_score(healthy_data)\n",
    "                \n",
    "                # Añadir puntuaciones a la lista\n",
    "                anomaly_scores.extend(scores.cpu().numpy())\n",
    "        \n",
    "        # Establecer umbral en el percentil especificado\n",
    "        self.threshold = np.percentile(anomaly_scores, percentile)\n",
    "        print(f'Threshold set to: {self.threshold:.6f} (percentile {percentile})')\n",
    "        return self.threshold\n",
    "    \n",
    "    def predict(self, data_loader):\n",
    "        \"\"\"Predice si un árbol está enfermo basándose en la puntuación de anomalía\"\"\"\n",
    "        if self.threshold is None:\n",
    "            raise ValueError(\"Threshold must be set before prediction using calculate_threshold\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_scores = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, labels in data_loader:\n",
    "                data = data.to(self.device)\n",
    "                scores, recon_errors, kl_divs = self.anomaly_score(data)\n",
    "                \n",
    "                # Clasificar como enfermo si la puntuación supera el umbral\n",
    "                predictions = (scores > self.threshold).cpu().numpy().astype(int)\n",
    "                \n",
    "                all_preds.extend(predictions)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_scores.extend(scores.cpu().numpy())\n",
    "        \n",
    "        return np.array(all_preds), np.array(all_labels), np.array(all_scores)\n",
    "    \n",
    "    def evaluate(self, data_loader):\n",
    "        \"\"\"Evalúa el rendimiento del detector de anomalías\"\"\"\n",
    "        predictions, labels, scores = self.predict(data_loader)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "        \n",
    "        # Calcular AUC-ROC\n",
    "        auc_roc = roc_auc_score(labels, scores)\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'auc_roc': auc_roc\n",
    "        }\n",
    "        \n",
    "        return results, predictions, labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efb576-165c-4495-b194-5336f107d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=1.0\n",
    "latent_dim=128\n",
    "detector = VAEAnomalyDetector(\n",
    "        input_channels=input_channels, \n",
    "        device=device, \n",
    "        latent_dim=latent_dim,\n",
    "        beta=beta\n",
    "    )\n",
    "print(\"Training VAE...\")\n",
    "train_losses, val_losses = detector.train(\n",
    "        train_loader, \n",
    "        test_loader, \n",
    "        epochs=2, \n",
    "        beta_annealing=True\n",
    "    )    # Calcular umbral\n",
    "print(\"Calculating threshold...\")\n",
    "threshold = detector.calculate_threshold(train_loader) \n",
    "    # Evaluar en el conjunto de prueba\n",
    "print(\"Evaluating model...\")\n",
    "results, predictions, labels, scores = detector.evaluate(test_loader)\n",
    "    # Imprimir resultados\n",
    "print(\"\\nResults:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a3639-9be2-4db5-96bd-3ed178e25c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385656e8-0939-4a82-b5ed-f276d129ed53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
