{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5ba023-108d-4b74-8331-e78a7054004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semillas aleatorias configuradas a: 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbd0f116bb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CherryTreeDataset import CherryTreeDataset\n",
    "from torchvision import transforms\n",
    "from funciones_auxiliares import plot_spectra, analyze_image, analyze_tiff_metadata, PATH, crop_central_region, set_seed, seed_worker\n",
    "from resnet_adapters import adapt_resnet_channels\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Subset\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet18_Weights, ResNet50_Weights\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
    "\n",
    "set_seed(42)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142e2225-0e32-410c-a7d2-2e1b1ebb5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dispositivo seleccionado es cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'El dispositivo seleccionado es {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb8529a-eba4-47c5-82bc-921a0b5924ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las transformaciones si son necesarias\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1280,960)),\n",
    "    #transforms.Lambda(lambda x: crop_central_region(x, center_ratio=0.8)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "formats = ('RGB.JPG', 'RED.TIF','GRE.TIF','NIR.TIF','REG.TIF')\n",
    "#formats = ('RGB.JPG','NIR.TIF','REG.TIF')\n",
    "#formats = ('RGB.JPG',)\n",
    "input_channels = 7\n",
    "dataset = CherryTreeDataset(PATH, transform=transform, formats = formats, concatenate = True, balance=False)\n",
    "\n",
    "healthy_indices = []\n",
    "disease_indices = []\n",
    "    \n",
    "for i, (_, label) in enumerate(dataset.samples):\n",
    "    if label == 0:  # Healthy\n",
    "        healthy_indices.append(i)\n",
    "    else:  # Disease\n",
    "        disease_indices.append(i)\n",
    "    \n",
    "    # Dividir los índices de árboles sanos en entrenamiento y validación\n",
    "np.random.shuffle(healthy_indices)\n",
    "\n",
    "train_healthy = healthy_indices[:int(0.8 * len(healthy_indices))]\n",
    "test_healthy = healthy_indices[int(0.8 * len(healthy_indices)):]\n",
    "train_disease = disease_indices[:int(0.8 * len(disease_indices))]\n",
    "test_disease = disease_indices[int(0.8 * len(disease_indices)):]\n",
    "    \n",
    "    # Los índices de árboles enfermos solo se usan para testing\n",
    "    # Create datasets\n",
    "train_dataset = Subset(dataset, train_healthy)\n",
    "val_dataset = Subset(dataset, test_healthy + test_disease)  # Incluimos enfermos solo para evaluación\n",
    "    \n",
    "    # Crear dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, worker_init_fn=seed_worker)\n",
    "test_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, worker_init_fn=seed_worker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd6dc02b-e4eb-46cc-974a-32f5ac7526b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder: Reducción progresiva de la dimensionalidad a través de más capas convolucionales\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Primera capa convolucional\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Segunda capa convolucional\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Tercera capa convolucional\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Cuarta capa convolucional\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        \n",
    "        # Decodificador\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Primera capa de transposición convolucional\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Segunda capa de transposición convolucional\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Tercera capa de transposición convolucional\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Capa final para reconstruir la imagen original\n",
    "            nn.ConvTranspose2d(32, input_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Para normalizar la salida entre 0 y 1\n",
    "        )\n",
    "        # Inicialización de pesos\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Propagación hacia adelante del encoder y decoder\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # Inicialización de los pesos de manera más robusta\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu', generator=torch.Generator().manual_seed(42))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class AnomalyDetector:\n",
    "    def __init__(self, input_channels, device='cuda', latent_dim=256):\n",
    "        self.device = device\n",
    "        self.model = ConvAutoencoder(input_channels).to(device)\n",
    "        self.input_channels = input_channels\n",
    "        self.threshold = None\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs=50, lr=1e-3, weight_decay=1e-5):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Entrenamiento (train_loader ya solo contiene árboles sanos)\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            for data, _ in train_loader:\n",
    "                data = data.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(data)\n",
    "                loss = criterion(outputs, data)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            \n",
    "            # Validación (solo evaluamos el error de reconstrucción en árboles sanos)\n",
    "            self.model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for data, labels in val_loader:\n",
    "                    # Solo evaluar en árboles sanos\n",
    "                    healthy_mask = labels == 0\n",
    "                    if not any(healthy_mask):\n",
    "                        continue\n",
    "                        \n",
    "                    data = data[healthy_mask].to(self.device)\n",
    "                    outputs = self.model(data)\n",
    "                    loss = criterion(outputs, data)\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            # Actualizar el scheduler\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), 'best_autoencoder.pth')\n",
    "                print(f'Modelo guardado epoca: {epoch+1}')\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')\n",
    "        \n",
    "        # Cargar el mejor modelo\n",
    "        self.model.load_state_dict(torch.load('best_autoencoder.pth'))\n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    def calculate_threshold(self, val_loader, percentile=95):\n",
    "        \"\"\"Calcula el umbral de error de reconstrucción basado en los datos de validación de árboles sanos\"\"\"\n",
    "        self.model.eval()\n",
    "        reconstruction_errors = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, labels in val_loader:\n",
    "                # Solo usar árboles sanos para calibrar el umbral\n",
    "                healthy_mask = labels == 0\n",
    "                if not any(healthy_mask):\n",
    "                    continue\n",
    "                    \n",
    "                healthy_data = data[healthy_mask].to(self.device)\n",
    "                outputs = self.model(healthy_data)\n",
    "                \n",
    "                # Calcular error por imagen\n",
    "                for i in range(healthy_data.size(0)):\n",
    "                    error = torch.mean((outputs[i] - healthy_data[i])**2).item()\n",
    "                    reconstruction_errors.append(error)\n",
    "        \n",
    "        # Establecer umbral en el percentil especificado\n",
    "        self.threshold = np.percentile(reconstruction_errors, percentile)\n",
    "        print(f'Threshold set to: {self.threshold:.6f} (percentile {percentile})')\n",
    "        return self.threshold\n",
    "    \n",
    "    def predict(self, data_loader):\n",
    "        \"\"\"Predice si un árbol está enfermo basándose en el error de reconstrucción\"\"\"\n",
    "        if self.threshold is None:\n",
    "            raise ValueError(\"Threshold must be set before prediction using calculate_threshold\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_scores = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, labels in data_loader:\n",
    "                data = data.to(self.device)\n",
    "                outputs = self.model(data)\n",
    "                \n",
    "                # Calcular error de reconstrucción por imagen\n",
    "                for i in range(data.size(0)):\n",
    "                    recon_error = torch.mean((outputs[i] - data[i])**2).item()\n",
    "                    # Si el error supera el umbral, clasificar como enfermo (anomalía)\n",
    "                    prediction = 1 if recon_error > self.threshold else 0\n",
    "                    all_preds.append(prediction)\n",
    "                    all_labels.append(labels[i].item())\n",
    "                    all_scores.append(recon_error)\n",
    "        \n",
    "        return np.array(all_preds), np.array(all_labels), np.array(all_scores)\n",
    "    \n",
    "    def evaluate(self, data_loader):\n",
    "        \"\"\"Evalúa el rendimiento del detector de anomalías\"\"\"\n",
    "        predictions, labels, scores = self.predict(data_loader)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "        \n",
    "        # Calcular AUC-ROC\n",
    "        auc_roc = roc_auc_score(labels, scores)\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'auc_roc': auc_roc\n",
    "        }\n",
    "        \n",
    "        return results, predictions, labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55efb576-165c-4495-b194-5336f107d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder...\n",
      "Modelo guardado epoca: 1\n",
      "Epoch 1/5, Train Loss: 0.885666, Val Loss: 0.827089\n",
      "Epoch 2/5, Train Loss: 0.878936, Val Loss: 0.827873\n",
      "Modelo guardado epoca: 3\n",
      "Epoch 3/5, Train Loss: 0.878583, Val Loss: 0.826702\n",
      "Epoch 4/5, Train Loss: 0.878400, Val Loss: 0.827060\n",
      "Epoch 5/5, Train Loss: 0.878547, Val Loss: 0.828194\n",
      "Calculating threshold...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89834/281356973.py:133: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load('best_autoencoder.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set to: 0.935662 (percentile 70)\n",
      "Evaluating model...\n",
      "\n",
      "Results:\n",
      "accuracy: 0.7083\n",
      "precision: 0.1500\n",
      "recall: 0.6429\n",
      "f1_score: 0.2432\n",
      "auc_roc: 0.8032\n"
     ]
    }
   ],
   "source": [
    "#detector = AnomalyDetector(input_channels=input_channels, device=device)\n",
    "print(\"Training autoencoder...\")\n",
    "train_losses, val_losses = detector.train(train_loader, test_loader, epochs=5) \n",
    "    # Calcular umbral\n",
    "print(\"Calculating threshold...\")\n",
    "threshold = detector.calculate_threshold(train_loader, percentile=70) \n",
    "    # Evaluar en el conjunto de prueba\n",
    "print(\"Evaluating model...\")\n",
    "results, predictions, labels, scores = detector.evaluate(test_loader)  \n",
    "    # Imprimir resultados\n",
    "print(\"\\nResults:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269d1fd-c110-4d59-9127-42f577d775dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc626b-75b2-4dde-bfad-7c81df84763c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
